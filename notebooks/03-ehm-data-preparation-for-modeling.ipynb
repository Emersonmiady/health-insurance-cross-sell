{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. IMPORTS\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DATA PREPARATION\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy\n",
    "dfp = pd.read_csv('../data/interim/hi_cs_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Creating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy sales channel 2\n",
    "dfp['policy_sales_channel2'] = dfp['policy_sales_channel'].copy().astype('int64').astype(str)\n",
    "dfp.loc[~dfp['policy_sales_channel'].isin([152, 26, 124]), 'policy_sales_channel2'] = 'others'\n",
    "dfp = pd.get_dummies(dfp, columns=['policy_sales_channel2'], dtype='int64')\n",
    "\n",
    "# Drop policy_sales_channel and redundant policy_sales_channel2_others\n",
    "dfp.drop(['policy_sales_channel', 'policy_sales_channel2_others'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicle damage\n",
    "dfp['vehicle_damage'] = dfp['vehicle_damage'].map({'Yes': 1, 'No': 0}).astype('int64')\n",
    "\n",
    "# Gender (1 = male, 0 = female)\n",
    "dfp['gender'] = dfp['gender'].map({'Male': 0, 'Female': 1}).astype('int64')\n",
    "\n",
    "# Vehicle age\n",
    "dfp['vehicle_age'] = dfp['vehicle_age'].map({'< 1 Year': 1, '1-2 Year': 2, '> 2 Years': 3}).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll test `vehicle_age` and `vehicle_age2` in feature importance methods. So, I'll include but drop one of them after."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Dropping some redundant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order of variables and drop: region_code and previously_insured\n",
    "wanted_vars = [\n",
    "       'id', 'age', 'vehicle_damage', 'annual_premium', 'vintage',\n",
    "       'famous_region', 'vehicle_age', 'vehicle_age2', \n",
    "       'hi_customer_profitability', 'famous_policy_sales_channel', \n",
    "       'policy_sales_channel2_124', 'policy_sales_channel2_152', \n",
    "       'policy_sales_channel2_26', 'gender', 'response'\n",
    "]\n",
    "\n",
    "dfp = dfp[wanted_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 continuous and **10 categorical features**. Maybe **catboost** will be a good propose for algorithm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data before training division\n",
    "dfp.to_csv('../data/interim/hi_cs_pre_training.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and y\n",
    "X = dfp.drop('response', axis=1)\n",
    "y = dfp['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving X_train and y_train\n",
    "X_train.to_csv('../data/processed/X_train.csv', index=False)\n",
    "y_train.to_csv('../data/processed/y_train.csv', index=False)\n",
    "\n",
    "# Saving X_test and y_test\n",
    "X_test.to_csv('../data/processed/X_test.csv', index=False)\n",
    "y_test.to_csv('../data/processed/y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Rescaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use some methods to rescale the data: **Min Max Scaler** and **Robust Scaler**. None of the continuous variables has a Normal distribution, aparently. If there are a lot of outliers, then Robust Scaler will be better. On the other hand, I'll use Min Max."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SCALERS DEFINED:**\n",
    "\n",
    "- **Min Max Scaler:**\n",
    "    - `age`\n",
    "    - `vintage`\n",
    "- **Robust Scaler:**\n",
    "    - `annual_premium`\n",
    "    - `hi_customer_profitability`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scalers and the columns they should be applied to\n",
    "scalers = [\n",
    "    (MinMaxScaler(), ['age', 'vintage']),\n",
    "    (RobustScaler(), ['annual_premium', 'hi_customer_profitability'])\n",
    "]\n",
    "\n",
    "# Define the column transformer with specified scalers\n",
    "transformers = [(scaler.__class__.__name__.lower(), scaler, cols) for scaler, cols in scalers]\n",
    "preprocessor = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "\n",
    "# Apply rescaling to columns\n",
    "X_train_rescaled = preprocessor.fit_transform(X_train)\n",
    "X_test_rescaled = preprocessor.transform(X_test)\n",
    "\n",
    "# Get feature names\n",
    "X_train_cols = list(preprocessor.get_feature_names_out())\n",
    "X_train_cols = [x.split('__')[1] for x in X_train_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving X_train_rescaled and X_test_rescaled\n",
    "pd.DataFrame(X_train_rescaled, columns=X_train_cols)\\\n",
    "    .to_csv('../data/processed/X_train_rescaled.csv', index=False)\n",
    "pd.DataFrame(X_test_rescaled, columns=X_train_cols)\\\n",
    "    .to_csv('../data/processed/X_test_rescaled.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
